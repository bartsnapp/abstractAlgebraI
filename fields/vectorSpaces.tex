\documentclass{ximera}

\input{../preamble.tex}

\author{Bart Snapp}

\title{Vector spaces}

\begin{document}
\begin{abstract}
  We review vector spaces.
\end{abstract}
\maketitle



\begin{definition}\index{K-vector space@$K$-vector space}\index{vector space@$K$-vector space}
  A \textbf{$\boldsymbol{K}$-vector space} is an Abelian group $(V,+)$
  along with a field $K$ such that we may multiply group elements by
  field elements, meaning that there is a binary operation $-\cdot-:
  K\times V \to V$ such that if $\nu,\mu\in V$ and $a,b,\in K$ we
  have:
\begin{description}
\item[Compatibility with scalars] $(ab)\cdot \nu = a\cdot (b\cdot \nu)$.
\item[Vectors distribute over scalars] $(a+b)\cdot \nu =
  a\cdot\nu + b\cdot \nu$.
\item[Scalars distribute over vectors] $a\cdot (\nu+\mu) =
  a\cdot \nu + a\cdot \mu$.
\item[Identity is respected] $1_K\cdot \nu = \nu$.
\end{description}
In this case, elements of the group $V$ are called \dfn{vectors} and
elements of the field $K$ are called \dfn{scalars}.
\end{definition}

\begin{exercise}
  Let $V$ be a $K$-vector space. If $\nu\in V$, prove that
  $0_K\cdot \nu = \vec{0}$.
\end{exercise}


\begin{example}[Euclidean space]
  Perhaps the most obvious vector space would be $\R^3$. This is an
  $\R$-vector space. It is also a $\Q$-vector space.
\end{example}



\begin{example}[Complex numbers]
  The set $\C$ is an $\C$-vector space, an $\R$-vector space, and a
  $\Q$-vector space.
\end{example}


\begin{example}[Polynomials]
  Let $K[x]$ be the set of all formal sums
  \[
  a_nx^n + a_{n-1}x^{n-1} + \dots + a_1 x + a_0
  \]
  where $n$ is a nonnegative integer and each $a_i \in K$. In this
  case, $K[x]$ is a $K$-vector space.
\end{example}




\begin{definition}
  Let $V$ be a $K$-vector space. A subset $W\subset V$ is a
  \textbf{$\boldsymbol K$-vector} \dfn{subspace} of $V$ if $W\subgp V$ and $W$
  is also a $K$-vector space.
\end{definition}

\begin{lemma}[Subspace criterion]\index{subspace criterion}
  Let $V$ be a $K$-vector space. $W\subset K$ is a subspace of $V$ if
  and only if
  \begin{enumerate}
  \item $W\ne \emptyset$.
  \item $W$ is closed under multiplication by scalars.
  \item $W$ is closed under vector addition.
  \end{enumerate}
  \begin{sketch}
    Check the definition of a vector space.
  \end{sketch}
\end{lemma}

\begin{definition}
  Let $V$ and $W$ be $K$-vector spaces. A \dfn{linear transformation}
  for $\nu,\mu\in V$ and $s\in K$ is a function $T:V\to W$ such that
    \begin{enumerate}
    \item $T(\nu+\mu) = T(\nu)+T(\mu)$.
    \item $T(s \nu) = sT(\nu)$.
    \end{enumerate}
\end{definition}

\begin{remark}
  We proved that every linear transformation is a matrix in
  Lemma~\ref{L:MT}.
\end{remark}

\begin{exercise}\index{kernel!linear transformation}
  Let $V$ and $W$ be $K$-vector spaces and let $T:V\to W$ be a linear
  transformation. Define the \textbf{kernel} of $T$ as follows:
  \[
  \ker(T) = \{\nu\in V: T(\nu) = 0\}\subset V.
  \]
  Prove that $\ker(T)$ is a $K$-vector subspace of $V$.
\end{exercise}

\begin{exercise}\index{image!linear transformation}
  Let $V$ and $W$ be $K$-vector spaces and let $T:V\to W$ be a linear
  transformation. Define the \textbf{image} of $T$ as follows:
  \[
  \im(T) = \{T(\nu): \nu\in V\}\subset W.
  \]
  Prove that $\im(T)$ is a $K$-vector subspace of $W$.
\end{exercise}







\begin{definition}
  Given a set of vectors $S$, in a $K$-vector space, $V$, the
  \dfn{span} of these vectors is
  \[
  \Span(S) = \{a\sigma+b\tau:\text{$s,t\in S$ and $a,b\in K$}\}.
  \]
\end{definition}


\begin{definition}
  Given a $K$-vector space $V$, a finite set of vectors
  \[
  \{\lambda_1,\dots,\lambda_n\}
  \]
  is said to be \dfn{linearly independent} if
  \[
  a_1\lambda_1 + a_2\lambda_2 +\cdots + a_n\lambda_n = 0\quad \Rightarrow \quad a_1= \cdots =a_n = 0.
  \]
  A finite set of vectors is set to be \dfn{linearly dependent} if
  they are not linearly independent.
\end{definition}

\begin{theorem}[Bases equivalences]
  Define an ordering on sets where $S \preceq T$ if $|S|\le |T|$. Let
  $B= \{\beta_1,\dots,\beta_n\}$ be a finite set of vectors in a
  $K$-vector space $V$. The following are equivalent:
  \begin{enumerate}
  \item $B = \min_{\preceq}\{S\subset V:\Span(S) = V\}$.
  \item $B$ is a linearly independent spanning set of vectors.
  \item $B = \max_{\preceq}\{S\subset V:\text{$S$ is a linearly independent set of vectors}\}$.
  \end{enumerate}
  Any finite set of vectors $B \subset V$ satisfying any of the
  equivalent conditions above is called a \dfn{basis} for $V$.
  \begin{proof}
    We will prove this in a ``circle.''

    
    $(\mathrm a)\Rightarrow(\mathrm b)$ We will assume that
    \[
    B = \min_{\preceq}\{S\subset V:\Span(S) = V\}.
    \]
    We must show that $B$ is a linearly independent spanning set of
    vectors. Seeking a contradiction, suppose that $B$ is not a
    linearly independent set of vectors. Then there exist $a_i\in K$
    such that
    \[
    a_1\beta_1 + a_2\beta_2 + \dots + a_n\beta_n = 0
    \]
    where not all the $a_i$ are nonzero. WLOG, we may assume that $a_n
    \ne 0$. Then we may write
    \[
    a_1\beta_1 + a_2\beta_2 + \dots + a_{n-1}\beta_{n-1}= -a_n \beta_n
    \]
    and we see that $B' = \{\beta_1,\dots,\beta_{n-1}\}$ spans
    $V$. But $B'\preceq B$, a contradiction. Hence $B$ is a linearly
    independent spanning set of vectors.

    

    $(\mathrm b)\Rightarrow(\mathrm c)$ We will assume that $B$ is a
    linearly independent spanning set of vectors. We must show that
    \[
    B = \max_{\preceq}\{S\subset V:\text{$S$ is a linearly independent set of vectors}\}.
    \]
    Suppose you want to construct another set $C$ of linearly
    independent vectors. Suppose that $\gamma_1$ is the first vector
    you choose to be in $C$. Since $\Span(B) = V$, we may write
    \begin{align}
      \gamma_1 &= c_1\beta_1 + c_2\beta_2 + \dots + c_n\beta_n \tag{$\bigstar$}\\
      \beta_1 &= c_1^{-1}(\gamma_1 -  c_2\beta_2 - \dots - c_n\beta_n.\notag
    \end{align}
    Note, WLOG $c_1 \ne 0$, as if it was zero, we could renumber our
    basis vectors.  Letting $B_1 = \{\gamma_1, \beta_2,\dots,
    \beta_n\}$, this means that $\beta_1\in \Span(B_1)$. We claim that
    $B_1$ is a set of linearly independent vectors. Suppose that for
    $a_i\in K$
    \[
    a_1 \gamma_1 + a_2 \beta_2 + \dots + a_n \beta_n = 0.
    \]
    Using $(\bigstar)$ to substitute, write
    \begin{align*}
      a_1(c_1\beta_1 + c_2\beta_2 + \dots + c_n\beta_n) + a_2 \beta_2 + \dots + a_n \beta_n = 0\\
      (a_1c_1) \beta_1 + (a_2+a_1c_2)\beta_2 + \dots + (a_n+a_1c_n)\beta_n = 0.
    \end{align*}
    Since $B$ is a set of linearly independent vectors, we conclude
    \begin{align*}
      (a_1c_1) &=0\\
      (a_2+a_1c_2) &=0\\
      &\vdots \\      
      (a_n+a_1c_n) &=0.
    \end{align*}
    Since $c_1\ne 0$, we see that $a_i = 0$, and hence $B_1$ is a set
    of linearly independent vectors. Inductively repeating this
    process for $\gamma_2\notin \Span(\gamma_1)$, and then for
    $\gamma_3 \notin \Span(\gamma_1,\gamma_2)$, we construct sets of
    linearly independent spanning vectors
    \begin{align*}
      B &= \{\beta_1,\beta_2,\dots,\beta_n\},\\
      B_1 &= \{\gamma_1,\beta_2,\dots,\beta_n\},\\
      B_2 &= \{\gamma_1,\gamma_2,\dots,\beta_n\},\\
      &\vdots \\
      C = B_n &= \{\gamma_1,\gamma_2,\dots,\gamma_n\}.\\
    \end{align*}
    Since $C$ is a set spanning linearly independent vectors, we
    cannot add another linearly independent vector. Since $|C| = |B|$,
    \[
    B = \max_{\preceq}\{S\subset V:\text{$S$ is a linearly independent set of vectors}\}.
    \]
    
    $(\mathrm c)\Rightarrow(\mathrm a)$ We will assume that
    \[
    B = \max_{\preceq}\{S\subset V:\text{$S$ is a linearly independent set of vectors}\}.
    \]
    We must show that
    \[
    B = \min_{\preceq}\{S\subset V:\Span(S) = V\}.
    \]
    Let $A$ be any spanning set. In this case, we can simply repeat
    the argument given for $(\mathrm b)\Rightarrow(\mathrm c)$ and see
    that $|A| = |B|$. Hence
    \[
    B = \min_{\preceq}\{S\subset V:\Span(S) = V\}.
    \]
    This concludes our proof of the equivalences.
  \end{proof}
\end{theorem}


Here is a picture that attempts to convey the situation:
\[
\begin{tikzpicture}
  \draw[white,thin,shading = axis, top color = white, bottom color = gray] (-2,2) -- (0,0)-- (2,2) -- (-2,2) -- cycle;
  \draw[white,thin,shading = axis, bottom color = white, top color = gray] (-2,-2) -- (0,0)-- (2,-2) -- (-2,-2) -- cycle;
  \filldraw (0,0) circle (3pt);
  \node[right] at (0,0) {$B$ is linearly independent and spans};
  \node at (0,1.5) {$\scriptstyle \Span(B) = V$};
  \node at (0,-1.5) {\tiny $B$  is linearly independent};
\end{tikzpicture}
\]
The cone above $B$ are all sets of vectors that span $V$. The cone
below $B$ are all sets of vectors that are linearly independent.



\begin{corollary}[Bases have the same order]
  Let $V$ be a $K$-vector space. If $B$ and $B'$ are two bases for $V$
  over $K$, then $|B| = |B'|$.
\end{corollary}


\begin{definition}
  Let $B$ be a basis for a $K$-vector space $V$. The \dfn{vector space
    dimension} of $V$ is the order of $B$,
  \[
  \dim_K(V) = |B|.
  \]
  If a vector space does not have a finite basis, then we say it is
  \dfn{infinite dimensional}.
\end{definition}


\begin{example}[Euclidean space]
  The $\R$-vector space $\R^3$ has dimension $3$ since it has basis vectors
  \[
  \begin{bmatrix}
    1\\
    0\\
    0
  \end{bmatrix},\quad
  \begin{bmatrix}
    0\\
    1\\
    0
  \end{bmatrix},\quad
   \begin{bmatrix}
    0\\
    0\\
    1
  \end{bmatrix}.
  \]
\end{example}


\begin{example}[Complex numbers]
  The complex numbers are a vector space over several different
  fields. Here we have
  \[
  \dim_{\C}(\C) = 1, \quad \dim_{\R}(\C) = 2, \quad \dim_{\Q}(\C) =\infty.
  \]
\end{example}

\begin{exercise}
  Find a basis for $\C$ as a $\C$-vector space. Find a basis for $\C$
  as an $\R$-vector space. In each case, prove your answer is correct.
\end{exercise}



\begin{example}[Polynomials of fixed degree]
  Let $P_3\subset \Q[x]$ be the polynomials up to and including degree
  $3$. In this case $\dim_{\Q}(\Q[x]) = 4$.
\end{example}

\begin{exercise}
  Find a basis for $P_3\subset \Q[x]$, the polynomials up to and
  including degree $3$, as a $\Q$-vector space. Prove your answer is
  correct.
\end{exercise}


\begin{theorem}[Bases and unique representation]
  Let $V$ be a $K$-vector space and $B = \{\beta_1,\dots,\beta_n$ be a
  basis for $V$. If
  \begin{align*}
  \alpha = a_1\beta_1 + a_2\beta_2 + \dots + a_n\beta_n\\
  \alpha = c_1\beta_1 + c_2\beta_2 + \dots + c_n\beta_n,
  \end{align*}
  where $a_i, c_i\in K$, then $a_i = c_i$ for $i =1,\dots, n$.
  \begin{sketch}
    Subtract the two equations above, combine like terms, and use the
    fact that a basis is a linearly independent set of vectors.
  \end{sketch}
\end{theorem}




\begin{theorem}[Quotient vector spaces]
  Given a $K$-vector space $V$ and a subspace $W\subset V$, the set of
  left cosets of $W$ form a $K$-vector space under coset
  addition. This $K$-vector space is denoted by $V/W$ and is
  pronounced ``$V$ modulo $W$.''
  \begin{proof}
    First note that by Theorem\ref{T:quotient}, $V/W$ is an Abelian
    group under coset addition. Now we must show that multiplication
    by field elements is \index{well-defined}well-defined and that
    $V/W$ is a $K$-vector space. Suppose that
    \[
    \nu + W = \mu + W.
    \]
    We must show that if $a\in K$,
    \[
    a\nu + W = a\mu + W.
    \]
    Since $aW = W$, this is true. All other conditions for $V/W$ to be
    a vector space are inherited from the fact that $V$ is a $K$-vector
    space.
  \end{proof}
\end{theorem}

\begin{corollary}[Dimensions and quotients]
  Let $V$ be a $K$-vector space and $W\subset V$ be a subspace. In
  this case,
  \[
  \dim_K(V) = \dim_K(W) + \dim_K(V/W)
  \]
\end{corollary}

%% \begin{example}[$\R^n$]
%% \end{example}


\begin{corollary}[Dimension and linear transformations]
  Let $V$ and $W$ be a $K$-vector spaces and let $T:V\to W$ be a
  linear transformation. In this case
  \[
  \dim_K(V) = \dim_K(\ker(T)) + \dim_K(\im(T)).
  \]
  \begin{sketch}
    Use Noether's isomorphism theorem, Theorem~\ref{T:NI}.
  \end{sketch}
\end{corollary}


\end{document}
