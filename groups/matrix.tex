\documentclass{ximera}

\input{../preamble.tex}

\author{Bart Snapp}
\title{Matrix groups}

\begin{document}
\begin{abstract}
  Sets of matrices can form groups.
\end{abstract}
\maketitle



Matrices are intimately connected to groups. Let's see if we can
convince you of this.


\section{Matrices are linear transformations}

Matrices are functions between vector spaces. Let's prove that the
linear transformations of $\R$-vector spaces are matrices. Our proof
will be general enough that one could change the set of scalars.

\begin{lemma}[Matricies are linear transformations]\label{L:MT}
  The function $T: V \to W$ from an $m$-dimensional vector space
  $V$ to a $n$-dimensional vector space $W$ is a linear transformation
  if and only if can be represented by a $n\times m$ matrix.
  \begin{proof}
    $(\Rightarrow)$ Recall the definition of a \index{linear transformation}linear transformation,
    for $\mu,\nu\in V$ and $s\in \R$:
    \begin{enumerate}
    \item $T(\mu+\nu) = T(\mu)+T(\nu)$.
    \item $T(s \nu) = sT(\nu)$.
    \end{enumerate}
    We will show that any function on vector spaces having these
    properties can be expressed as a matrix over the set of scalars.

    The image of $T$ is completely determined by the action of
    $T$ on a basis. Let $\{\beta_1,\dots,\beta_m\}$ be a
    basis for $V$. Then if $\nu\in V$, we may write
    \begin{align*}
      \nu &= \begin{bmatrix}
        a_1\\
        \vdots \\
        a_m
        \end{bmatrix}\\
      &=a_1\beta_1 + \dots + a_m\beta_m.
    \end{align*}
    Now,
    \begin{align*}
      T(\nu)&=T(a_1\beta_1 + \dots + a_m\beta_m)\\
      &= T(a_1\beta_1) + \dots + T(a_m\beta_m) \\
      &= a_1T(\beta_1) + \dots + a_mT(\beta_m).
    \end{align*}
    Hence, to define a linear transformation $T$, we only need
    to know where $T$ maps each basis element. In this case, we
    can represent
    \[
    T = \begin{bmatrix}
      T(\beta_1)| & \cdots &| T(\beta_m)
    \end{bmatrix}
    \]
    where each $T(\beta_i)$ is a column vector of length $n$.
    So, we may write
    \[
    T(\nu) = \begin{bmatrix}
      T(\beta_1) |& \cdots & |T(\beta_m)
    \end{bmatrix} \begin{bmatrix}
        a_1\\
        \vdots \\
        a_m
        \end{bmatrix}.
    \]
    We have now shown that every linear transformation can be thought
    of as an $n\times m$ matrix.

      $(\Leftarrow)$ Let $M$ be an $n\times m$ matrix. Since matrix
    multiplication distributes over vector addition,
      \[
      M(\mu+\nu)  = M\cdot \mu + M\cdot \nu.
      \]
      Also, we know that with matrix multiplication,
      \[
      s M \nu = M(s\nu).
      \]
      Hence any $n\times m$ matrix is a linear transformation from an
      $m$-dimensional vector space to an $n$-dimensional vector
      space.
  \end{proof}
\end{lemma}



\begin{definition}
  The set $GL(n)$ is the set of invertible $n\times n$ matrices with
  entries in $\R$. This group is called the \dfn{general linear
    group}.
\end{definition}

\begin{exercise}
  Prove that $GL(n)$ is a group under matrix multiplication.
\end{exercise}



\section{Determinants}

In mathematics, we often want to reduce something complicated to a
single number. Determinants are a way to reduce a matrix to a single
number.

\begin{definition}  \label{D:determinants}
A \dfn{determinant}\textbf{ function} of an $n\times n$ matrix $M$
with entries in $\R$ is a real number $D(M)$ such that
\begin{itemize}
\item If $M$ is lower triangular, then $D(M)$ is the product of the
  diagonal entries of $M$.
\item The determinant of the transpose of a matrix is equal to the
  determinant of the matrix, $D(M^\transpose)=D(M)$.
\item Let $N$ be an $n\times n$ matrix, then
  \[
  D(MN) = D(M) D(N).
  \]
\end{itemize}
\end{definition}


\begin{lemma}[The determinant function is unique]  
  There is only one determinant function. It is denoted $\det(M)$ and
  called the \dfn{determinant} of $M$.
  \begin{sketch}
    See a text on linear algebra.
  \end{sketch}
\end{lemma}



\begin{definition}
  A matrix $M:\R^n\to \R^n$ satisfying
  \[
  M^\transpose \cdot M=I
  \]
  is called an \dfn{orthogonal} matrix. We denote the set of $n\times
  n$ orthogonal matrices by $O(n)$.
\end{definition}


\begin{exercise}
  Prove that if $M\in O(n)$, then $\det(M) = \pm 1$.
\end{exercise}

\begin{exercise}
  Is it true that if $\det(M) = \pm 1$, then $M \in O(n)$?
  \begin{hint}
    No, find a counterexample in $O(2)$.
  \end{hint}
\end{exercise}


\begin{exercise}
  Prove that $O(n)$ is a group under matrix multiplication.
\end{exercise}




\begin{lemma}[Isometries and orthogonality]
  A matrix $M$ is orthogonal if and only if it defines an isometry via
  \[
  \begin{bmatrix}
    x' \\ y' \\ z'
  \end{bmatrix}
  = M \begin{bmatrix} x \\ y \\ z\end{bmatrix}.
  \]
  \begin{sketch}
    Note that the square of the distance between the points $x_{1}$
    and $x_{2}$ is the dot product of the vector%
    \[
    \nu=x_{2}-x_{1}%
    \]
    with itself.  Also recall the identity
    $(AB)^\transpose=B^\transpose A^\transpose$.
    
    $(\Rightarrow)$ If $M$ is orthogonal, write
    \[
    (M\nu) \bullet (M\nu)
    \]
    and deduce that this equals ${\nu}\bullet{\nu}$.

    $(\Leftarrow)$ Suppose that $M$ defines an isometry. Explain why
    this means that
    \[
    ( M{\nu}) \bullet ( M{\nu})=
    {\nu} \bullet {\nu}
    \]
    for every ${\nu}$.  Now rewrite as:
    \[
    \nu^\transpose M^\transpose \cdot M\nu=\nu^\transpose
    \cdot{\nu}.
    \]
    Write
    \[
    {\nu} =
    \begin{bmatrix}
      a_1 \\ a_2 \\ \vdots \\ a_n
    \end{bmatrix}
    \]
     and view the equation 
    \[
    \nu^\transpose M^\transpose \cdot M\nu=\nu^\transpose
    \cdot{\nu}
    \]
    as a polynomial equation in the variables $a_1,\dots,a_n$. Since
    polynomials are equal if and only if their coefficients are equal
    this should finish the proof.
  \end{sketch}
\end{lemma}





\begin{definition}
  The set $SO(n)$ is the set of orthogonal matrices with entries in
  $\R$ and determinant equal to $1$. This is called the \dfn{special
    orthogonal group}.
\end{definition}

\begin{exercise}
  Prove that $SO(n)$ is a group under matrix multiplication.
\end{exercise}


\begin{exercise}
  Prove that:
  \[
  SO(n) \subset O(n) \subset GL(n)
  \]
\end{exercise}


\begin{exercise}
  Find a matrix $M$ such that $\det(M) =1$ and $M\notin SO(n)$. 
\end{exercise}



\section{Classification}



\begin{lemma}[Classification of \textit{SO}(2)]\label{L:SO}
  If $M\in SO(2)$, then
  \[
  M =
  \begin{bmatrix}
    \cos(\theta) & -\sin(\theta) \\
    \sin(\theta) & \cos(\theta)
  \end{bmatrix}
  \]
  and $M$ is a rotation about the origin.
  \begin{proof}
    Let
    \[
    M=
    \begin{bmatrix}
      a & b \\
      c & d
    \end{bmatrix}.
    \]
    Since $SO(2) \subset O(2)$, we have that
    \[
    M^\transpose M =
    \begin{bmatrix}
      a^2+c^2 & ab+cd\\
      ab + cd & b^2+d^2
    \end{bmatrix}
    \]
    This means that $b= \pm c$ and $d = \mp a$. Hence
    \[
    M = \begin{bmatrix}
      a & -c \\
      c & a
    \end{bmatrix}
    \quad\text{or}\quad
    M = \begin{bmatrix}
      a & c \\
      c & -a
    \end{bmatrix}.
    \]
    However, we also know that $\det(M) = 1$.  So
    \[
    \det\left(\begin{bmatrix}
      a & -c \\
      c & a
    \end{bmatrix}\right) = 1\quad\text{or}\quad
     \det\left(\begin{bmatrix}
      a & c \\
      c & -a
     \end{bmatrix}\right) = 1.
     \]
     Of these, only the left one is possible.  Thus,
    \[
     M = \begin{bmatrix}
      a & -c \\
      c & a
    \end{bmatrix}
     \]
     where $a^2 + c^2 = 1$. This means that
     \[
     M =
     \begin{bmatrix}
       \cos(\theta) & -\sin(\theta) \\
       \sin(\theta) & \cos(\theta)
     \end{bmatrix}
     \]
     and is a rotation. Note that we could have switched sine and
     cosine, changing the direction of the rotation.
  \end{proof}
\end{lemma}





\begin{theorem}[Classification of \textit{O}(2)]
  If $M\in O(2)$, then $M$ is a rotation about the origin or a
  reflection across a line through the origin.
  \begin{proof}
    Working exactly as in the proof of the classification of $SO(n)$,
    Lemma~\ref{L:SO}, we find
    \[
    M = \begin{bmatrix}
      a & -c \\
      c & a
    \end{bmatrix} \quad\text{or}\quad
    M = \begin{bmatrix}
      a & c \\
      c & -a
    \end{bmatrix}.
    \]
    The first is a rotation. The second can be viewed as the product
    \[
    \begin{bmatrix}
      \cos(\theta) & -\sin(\theta) \\
      \sin(\theta) & \cos(\theta)
    \end{bmatrix}
    \underbrace{\begin{bmatrix}
      1 & 0 \\
      0 & -1
    \end{bmatrix}}_{\text{reflection across $x$-axis}}
    \]
    for some value of $\theta$. Thus every matrix in $O(2)$ is a
    rotation about the origin or a reflection across a line through
    the origin.
  \end{proof}
\end{theorem}






\section{The quaternions}

Now we introduce a group that is fundamental for physics and computer
graphics called the \textit{quaternions}.

\begin{definition}
The \dfn{quaternions} is the set
\[
Q_8 = \{1,-1,i,-i,j,-j,k,-k\}
\]
where the elements follow the rules
  \[
  i^2 = j^2 = k^2 = -1,
  \]
and
\begin{align*}
  ij &= k,  & jk &= i, & ki &= j, \\
  ji &= -k, & kj &= -i, & ik &= -j. \\
\end{align*}
\end{definition}


As you go around counterclockwise in the picture below
\[
\begin{tikzpicture}
  \draw[ultra thick,->] (.94,-.34) arc (-20:80:1cm);
  \draw[ultra thick,->] (-.17,.98) arc (100:200:1cm);
  \draw[ultra thick,->] (-.77,-.64) arc (220:320:1cm);
  \node at (0,1) {$i$};
  \node at (-.87,-.5) {$j$};
  \node at (.87,-.5) {$k$};
\end{tikzpicture}
\]
the products are positive. We will show that $Q_8$ is a
group. Moreover, we will give a \dfn{representation} of the group as a
set of matrices in $GL(4)$:
  \begin{align*}
    1 &:=
    \begin{bmatrix}
      1 & 0 & 0 & 0 \\
      0 & 1 & 0 & 0 \\
      0 & 0 & 1 & 0 \\
      0 & 0 & 0 & 1
    \end{bmatrix}
    &
    i &:=
    \begin{bmatrix}
      0 & -1 & 0 &  0 \\
      1 &  0 & 0 &  0 \\
      0 &  0 & 0 & -1 \\
      0 &  0 & 1 &  0
    \end{bmatrix} \\
    j &:=
    \begin{bmatrix}
      0 &  0 & -1 &  0 \\
      0 &  0 &  0 &  1 \\
      1 &  0 &  0 &  0 \\
      0 & -1 &  0 &  0 
    \end{bmatrix}
    &
    k &:=
    \begin{bmatrix}
      0 &  0 &  0 & -1 \\
      0 &  0 & -1 &  0 \\
      0 &  1 &  0 &  0 \\
      1 &  0 &  0 &  0 
    \end{bmatrix}
  \end{align*}

\begin{example}[The quaternion group]
  The eight elements
  \[
  \{1,-1,i,-i,j,-j,k,-k\}
  \]
  form a group under (matrix) multiplication. This group is known as
  the \dfn{quaternion group}, and is also called (and denoted)
  $Q_{8}$.
  \begin{proof}
    Let's check the conditions for this to be a group. We know that
    the operation is associative, since functional composition is
    associative (and matrix multiplication is function composition),
    Lemma~\ref{L:funCompAss}.

    There is an identity element, $1$.
    
    We must show that this set is closed under function composition.
    To see this we will make a Cayley table. Write with me:
    \begin{gather*}
    \renewcommand{\arraystretch}{1.6}
    \begin{array}{c!{\vline width 2pt}cccccccc}
      (Q_8,\cdot) & 1 & -1 \cellcolor{black!6!white} & i \cellcolor{red!6!white} & -i \cellcolor{red!12!white} & j \cellcolor{blue!6!white} & -j \cellcolor{blue!12!white} & k \cellcolor{yellow!6!white} & -k \cellcolor{yellow!12!white} \\ \Xhline{2pt}
      1 & 1 & -1 \cellcolor{black!6!white} & i \cellcolor{red!6!white} & -i \cellcolor{red!12!white} & j \cellcolor{blue!6!white} & -j \cellcolor{blue!12!white} & k \cellcolor{yellow!6!white} & -k \cellcolor{yellow!12!white} \\
      -1 \cellcolor{black!6!white}& -1 \cellcolor{black!6!white} & 1 & -i \cellcolor{red!12!white} & i \cellcolor{red!6!white} & -j \cellcolor{blue!12!white} & j \cellcolor{blue!6!white} & -k \cellcolor{yellow!12!white} & k \cellcolor{yellow!6!white} \\
      i \cellcolor{red!6!white}& i \cellcolor{red!6!white} & -i \cellcolor{red!12!white} & -1 \cellcolor{black!6!white}  & 1 & k \cellcolor{yellow!6!white} & -k \cellcolor{yellow!12!white} & -j \cellcolor{blue!12!white} & j \cellcolor{blue!6!white} \\
      -i \cellcolor{red!12!white}& -i \cellcolor{red!12!white} & i \cellcolor{red!6!white} & 1  & -1  \cellcolor{black!6!white}& -k \cellcolor{yellow!12!white} & k \cellcolor{yellow!6!white} & j \cellcolor{blue!6!white} & -j \cellcolor{blue!12!white} \\
      j \cellcolor{blue!6!white}& j \cellcolor{blue!6!white} & -j \cellcolor{blue!12!white} & -k \cellcolor{yellow!12!white}  & k\cellcolor{yellow!6!white} & -1 \cellcolor{black!6!white} & 1  & i \cellcolor{red!6!white} & -i \cellcolor{red!12!white} \\
      -j \cellcolor{blue!12!white}& -j \cellcolor{blue!12!white} & j \cellcolor{blue!6!white} & k \cellcolor{yellow!6!white}  & -k\cellcolor{yellow!12!white} & 1  & -1 \cellcolor{black!6!white} & -i \cellcolor{red!12!white} & i \cellcolor{red!6!white} \\
      k \cellcolor{yellow!6!white}& k \cellcolor{yellow!6!white} & -k \cellcolor{yellow!12!white} & j \cellcolor{blue!6!white}  & -j\cellcolor{blue!12!white} & -i \cellcolor{red!12!white} & i\cellcolor{red!6!white}  & -1 \cellcolor{black!6!white} & 1  \\
      -k \cellcolor{yellow!12!white}& -k \cellcolor{yellow!12!white} & k \cellcolor{yellow!6!white} & -j \cellcolor{blue!12!white}  & j\cellcolor{blue!6!white} & i \cellcolor{red!6!white} & -i\cellcolor{red!12!white}  & 1 & -1 \cellcolor{black!6!white}
    \end{array}
    \end{gather*}
    From this, we see that $Q_8$ is closed under function composition,
    and that every element has an inverse. Hence $Q_8$ is a group.
  \end{proof}
\end{example}

\begin{exercise}
  Find the order of every element of $Q_8$.
\end{exercise}


\begin{exercise}
   Show that the quaternion group $Q_8$ is not isomorphic to the
   dihedral group $D_4$.
\end{exercise}

\begin{exercise}
  Prove that $Q_8$ is generated by $\{i, j\}$ and make a Cayley table
  for $Q_8$ with entries
  \[
  1, i, i^2, i^3, j, ij, i^2j, i^3j.
  \]
\end{exercise}


For some interesting extra reading check out:
\begin{itemize}
\item \link[\textit{The origin of quaternions}, T.\ Bannon, The College Mathematics Journal, Volume 46, 2015]{https://doi-org.proxy.lib.ohio-state.edu/10.4169/college.math.j.46.1.43}.
\item \link[\textit{Applications of group theory in particle physics}, F.\ Dyson, SIAM Review, Volume 8, 1966]{https://www.jstor.org/stable/2028169}.%% suggested by Muhammad Akbar
\item \link[\textit{Skewed rotation symmetry group detection}, S.\ Lee and Y.\ Liu, IEEE Transactions on Pattern Analysis and Machine Intelligence, September, 2010]{https://www.researchgate.net/publication/45200129_Skewed_Rotation_Symmetry_Group_Detection}.
\item \link[\textit{Finite groups of $2\times 2$ integer matrices}, G.\ Mackiw, Mathematics Magazine, December, 1996]{https://www.maa.org/sites/default/files/George_Mackiw20823.pdf}.
\end{itemize}




\end{document}
